{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "68f69423",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#<1#(70337463)~%(1904052177) #>1#(64727859):(64727859)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlosses\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_categorical_crossentropy\n\u001b[1;32m      5\u001b[0m \u001b[39m#<1#(64727859)~%(-1952786418) #>1#(17199287):(17199287)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "#>1#(70337463):(70337463)\n",
        "import matplotlib.pyplot as plt\n",
        "#<1#(70337463)~%(1904052177) #>1#(64727859):(64727859)\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "#<1#(64727859)~%(-1952786418) #>1#(17199287):(17199287)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout\n",
        "#<1#(17199287)~%(533338258) #>1#(60489680):(60489680)\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#<1#(60489680)~%(696278483)\n",
        "# Leave for imports"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615f3e4c",
      "metadata": {},
      "source": [
        "Run the following !pip3 cells to install scikit-plot and tensorflow which are needed for this sandbox."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28b5cbac",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install scikit-plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fd3374c",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df6e449",
      "metadata": {},
      "source": [
        "We're a little briefer in the sandbox since it builds on the Neural Network Classifer sandbox."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69706a23",
      "metadata": {},
      "source": [
        "# Neural Network Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "287dc421",
      "metadata": {},
      "source": [
        "This time, we will build from the Neural Network Classifier sandbox. We want you to see that you don't have to rework the notebook into a regression model, as opposed to a classifer, you only need to specify what you want to predict. Arctic fox will know that the data being predicting matches a regression model. It will apply this difference through out the code:\n",
        "- the predicted column won't be one-hot encoded\n",
        "- the final layer of the model won't be a softmax\n",
        "- accuracy won't be included in the compilation or visualization\n",
        "- the confusion matrix is replaced with a graph of the actual vs predicted \n",
        "\n",
        "And others. Check out the sand box and, as always, feel free to make changes. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307d8ec9",
      "metadata": {},
      "source": [
        "Again, the wine column lacks headers, predicting column 7 will predict the Flavanoids in each wine. What are those? We don't really know... But we do know its a regression column! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43279c7e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#[Data wine.csv --predict 7]#@60489680 #>1#(60489680):(60489680)\n",
        "wine = pd.read_csv('wine.csv')\n",
        "wineAllFeatures = wine.copy()\n",
        "\n",
        "column0ToNumber = {\n",
        "    1: 0, 2: 1, 3: 2\n",
        "}\n",
        "\n",
        "wineAllFeatures.iloc[:,0] = wineAllFeatures.iloc[:,0].apply(lambda cell : column0ToNumber[cell])\n",
        "\n",
        "wineAllLabels = wineAllFeatures.iloc[:,7]\n",
        "wineAllFeatures.drop(wineAllFeatures.columns[7], axis=1, inplace=True)\n",
        "wineAllFeatures = np.array(wineAllFeatures)\n",
        "\n",
        "wineTrainingFeatures, wineTestFeatures, wineTrainingLabels, wineTestLabels = train_test_split(wineAllFeatures, wineAllLabels, test_size=0.2)\n",
        "#<1#(60489680)~%(-1397202326)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59170990",
      "metadata": {},
      "source": [
        "Play around with different size networks. When we were testing the wine dataset, a smaller network seemed to work better. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408e0de0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#[NN --denseLayers 8 --denseStart 24 --denseEnd 8 --dropOutRatio 1:4]#@17199287 #>1#(17199287):(17199287)\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(24, activation='relu', input_shape=(13,)))\n",
        "model.add(Dense(19, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(13, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(11, activation='relu'))\n",
        "model.add(Dense(9, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "#<1#(17199287)~%(-1745109498)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_3e881981",
      "metadata": {},
      "outputs": [],
      "source": [
        "#>1#(17199287):(17199287)\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=Adam()\n",
        "    )\n",
        "#<1#(17199287)~%(-672719537)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_3b35f415",
      "metadata": {},
      "outputs": [],
      "source": [
        "#>1#(17199287):(17199287)\n",
        "model.summary()\n",
        "#<1#(17199287)~%(1975814818)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a674a3e",
      "metadata": {},
      "source": [
        "Don't be afraid to train quite a bit. We ended up training for around 1500 total epochs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1c6f5b",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#[Train --epochs 100]#@64727859 #>1#(64727859):(64727859)\n",
        "# Fit data to model\n",
        "history = model.fit(\n",
        "    wineTrainingFeatures,\n",
        "    wineTrainingLabels,\n",
        "    batch_size=1,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_split=0.2\n",
        ")\n",
        "#<1#(64727859)~%(-977557149)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_7b299ecf",
      "metadata": {},
      "outputs": [],
      "source": [
        "#>1#(64727859):(64727859)\n",
        "# Generate generalization metrics\n",
        "score = model.evaluate(wineTestFeatures, wineTestLabels, verbose=0, batch_size=1)\n",
        "print(f'Test loss: {score}')\n",
        "#<1#(64727859)~%(-1280751450)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0e44f7",
      "metadata": {},
      "source": [
        "View the loss and predictions. With the --predictions item, Arctic Fox will graph the predictions and labels so you can visually see how close the two are. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f3d008",
      "metadata": {},
      "outputs": [],
      "source": [
        "#[Visualize --loss --predictions]#@70337463 #>1#(70337463):(70337463)\n",
        "#***Plot history: Loss\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "plt.plot(history.history['val_loss'], color='orange', label='val')\n",
        "plt.title('Train and Validation Loss History')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#<1#(70337463)~%(-52552)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_2435569e",
      "metadata": {},
      "outputs": [],
      "source": [
        "#>1#(70337463):(70337463)\n",
        "#***Automated for item: --predict. View predicted values vs actual label\n",
        "prediction = model.predict(wineTestFeatures)\n",
        "labels = [label for label in wineTestLabels]\n",
        "nonArrayPrediction = [value[0] for value in prediction]\n",
        "zipped = zip(labels, nonArrayPrediction)\n",
        "sortedList = sorted(zipped, key=lambda value: value[0])\n",
        "sortedLabels = [value[0] for value in sortedList]\n",
        "sortedPredictions = [value[1] for value in sortedList]\n",
        "\n",
        "xAxis = np.arange(0, len(prediction), 1)\n",
        "plt.scatter(xAxis, sortedLabels, label='actual', color='lawngreen')\n",
        "plt.scatter(xAxis, sortedPredictions, label='prediction', color='blueviolet')\n",
        "plt.legend(loc='upper left')\n",
        "plt.xlabel('index')\n",
        "#<1#(70337463)~%(2121028170)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468d5296",
      "metadata": {},
      "source": [
        "There you have it! You can train the network more to improve its performance, try changing the model archiecture, etc. And then, check out the next sandbox!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c918d6d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
